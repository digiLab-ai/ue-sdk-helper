{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6392db1",
   "metadata": {},
   "source": [
    "# Uncertainty Engine SDK example workflows - train and predict a 1D model\n",
    "\n",
    "This notebook goes through how you would set up a workflow to train and save a machine-learning model using the `TrainModel` node and then make predictions on new data using the `PredictModel` node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a334f5",
   "metadata": {},
   "source": [
    "Start by importing and initializing the `Client`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf999f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UE_ACCOUNT_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUE_ACCOUNT_ID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01muncertainty_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client, Environment\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mamentum_librti\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msettings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ACCOUNT_ID\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:714\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'UE_ACCOUNT_ID'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"UE_ACCOUNT_ID\"]\n",
    "from uncertainty_engine import Client, Environment\n",
    "from amentum_librti.config.settings import ACCOUNT_ID\n",
    "\n",
    "client = Client()\n",
    "client.authenticate(ACCOUNT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9f701",
   "metadata": {},
   "source": [
    "With useful imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from amentum_librti.plotting.plots import plot_1d\n",
    "from amentum_librti.utils.helper import get_presigned_url\n",
    "\n",
    "cwd = os.getcwd()\n",
    "repo_root = os.path.dirname(cwd)\n",
    "data_directory = repo_root+\"/src/amentum_librti/data/\"  # Change this to your data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465b463",
   "metadata": {},
   "source": [
    "## Part 1: Building and running a **train** workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd74d8",
   "metadata": {},
   "source": [
    "### Viewing the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef237c09",
   "metadata": {},
   "source": [
    "Once you have initialised the Uncertainty Engine client you can use the `list_nodes` method to find your node information. Fields such as the `description`, `inputs` and `outputs` are particularly useful for building your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with node IDs as keys\n",
    "nodes = client.list_nodes()\n",
    "nodes_by_id = {node[\"id\"]: node for node in nodes}\n",
    "\n",
    "# Print the details of the `TrainModel` node\n",
    "pprint(nodes_by_id[\"TrainModel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097715e6",
   "metadata": {},
   "source": [
    "Now we know that the `TrainModel` node needs the following inputs:\n",
    "- **Input Dataset:** Train input data\n",
    "- **Output Dataset:** Target output data\n",
    "- **Model Config:** A model config node specifying the parameters we wish to use for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c866f",
   "metadata": {},
   "source": [
    "### Creating our train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb25a47",
   "metadata": {},
   "source": [
    "In this example we will use some synthetic data to demonstrate how it can be used to train a model. \n",
    "We need two datasets, one with fewer data points (to train) and one with more data points (to test).\n",
    "\n",
    "The data can be generated via https://librti-toy.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8be2fa",
   "metadata": {},
   "source": [
    "Produce the datasets, and save your data to a known directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d64f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'train_corrosion_dataset.csv'\n",
    "test_filename = 'test_corrosion_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4045e1",
   "metadata": {},
   "source": [
    "Now we will load these as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1cf7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_directory+train_filename)\n",
    "test_df = pd.read_csv(data_directory+test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a4215",
   "metadata": {},
   "source": [
    "Let's check which parameters we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ff199",
   "metadata": {},
   "source": [
    "### Configuring our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e09f2a",
   "metadata": {},
   "source": [
    "As we can see by the `TrainModel` node info, it needs a `ModelConfig`. To define this ModelConfig we need a ModelConfig node. Like for the TrainModel node we can examine the inputs and outputs of the ModelConfig node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print `ModelConfig` node details\n",
    "pprint(nodes_by_id[\"ModelConfig\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c4eee",
   "metadata": {},
   "source": [
    "The `ModelConfig` node accepts several optional parameters that control model training. However, as none of the inputs are required we can just use the default input parameters for now. This will configure our model as a `SingleTaskGP` which is ideal for our regression task. A `SingleTaskGP` (Single Task Gaussian Process) models the relationship between a single input and output variable while providing uncertainty estimates alongside predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6222548",
   "metadata": {},
   "source": [
    "### Constructing a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73c79a",
   "metadata": {},
   "source": [
    "First, import and initialise the `Graph` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f36888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.graph import Graph\n",
    "\n",
    "# Create a new graph\n",
    "train_graph = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.nodes.base import Node\n",
    "\n",
    "# Define the model config node\n",
    "model_config = Node(\n",
    "    node_name=\"ModelConfig\",\n",
    "    label=\"Model Config\",\n",
    ")\n",
    "\n",
    "# Add node to the graph and connect it to the train node\n",
    "train_graph.add_node(model_config)\n",
    "\n",
    "# Add a handle to the the config output\n",
    "output_config = model_config.make_handle(\"config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267288e8",
   "metadata": {},
   "source": [
    "Then we can start adding nodes to the graph. The first node we will add is the `TrainModel` node, with our train `x` and `y` CSVs as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbec887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X values to CSV string\n",
    "input_csv = train_df[['temperature_c']].to_csv(index=False)\n",
    "\n",
    "# Convert Y values to CSV string\n",
    "output_csv = train_df[['comp_Fe']].to_csv(index=False)\n",
    "\n",
    "# Create the train node with the data as input\n",
    "train_model = Node(\n",
    "    node_name=\"TrainModel\",\n",
    "    label=\"Train Model\",\n",
    "    config=output_config,\n",
    "    inputs={\"csv\": input_csv},\n",
    "    outputs={\"csv\": output_csv}\n",
    ")\n",
    "\n",
    "# Add the node to the graph\n",
    "train_graph.add_node(train_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f7d36",
   "metadata": {},
   "source": [
    "### Assigning an output node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312a91e5",
   "metadata": {},
   "source": [
    "Now our graph has been built we can use an output node to decide how we wish to collect the output. The output nodes we could use here are:\n",
    "- **Download:** To download the model JSON using an AWS pre-signed url.\n",
    "- **Save:** To save the model JSON to the Uncertainty Engine cloud.\n",
    "\n",
    "First lets make a handle for the output `model` of the `Train` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = train_model.make_handle(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef8c47",
   "metadata": {},
   "source": [
    "In this case we will use the `Download` node to get a pre-signed URL for our trained model so we can use it for the `Predict` part of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Download node\n",
    "download = Node(\n",
    "  node_name=\"Download\",\n",
    "  label=\"Download\",\n",
    "  file=output_model\n",
    ")\n",
    "\n",
    "# Add the download node to the graph and connect it to the train node\n",
    "train_graph.add_node(download)\n",
    "\n",
    "# Print graph to check the structure\n",
    "pprint(train_graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575839d0",
   "metadata": {},
   "source": [
    "### Executing a workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc75f1e",
   "metadata": {},
   "source": [
    "Create the executable workflow by wrapping our graph in the `Workflow` node and defining the `requested_output` as the output handle of the `Download` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uncertainty_engine.nodes.workflow import Workflow\n",
    "\n",
    "# Define our output handles\n",
    "output_download_model = download.make_handle(\"file\")\n",
    "\n",
    "# Wrap the graph in a workflow node\n",
    "train_workflow = Workflow(\n",
    "    graph=train_graph.nodes,\n",
    "    input=train_graph.external_input,\n",
    "    external_input_id=train_graph.external_input_id,\n",
    "    requested_output={\n",
    "        \"Trained Model\": output_download_model.model_dump(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249edb3b",
   "metadata": {},
   "source": [
    "Now, we can execute the workflow by running `client.run_node(workflow)` and passing the workflow object. This may take a minute for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_response = client.run_node(train_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9646b7e",
   "metadata": {},
   "source": [
    "Following the presigned URL will download the trained model. In the following cell we use this link to define our `model_json` so that it can be used for our `predict` workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474450a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the presigned URL from the response\n",
    "trained_model_url = train_response.outputs[\"outputs\"][\"Trained Model\"]\n",
    "\n",
    "\n",
    "\n",
    "# Get the model from the presigned URL\n",
    "model_response = get_presigned_url(trained_model_url)\n",
    "model_json = model_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3288b4",
   "metadata": {},
   "source": [
    "## Part 2: Building and running a **predict** workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e704ec7",
   "metadata": {},
   "source": [
    "Next, we will use the saved model json to make predictions on a sample dataset. If we take a look at the `PredictModel` node information we can see that the following inputs are needed to run the node:\n",
    "- **Dataset:** The input data on which to make the output predictions (this will be our `test_df` dataset)\n",
    "- **Model:** The pre-trained model to be used to make the predictions\n",
    "- **Seed (optional):** A random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0621af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print `PredictModel` node details\n",
    "pprint(nodes_by_id[\"PredictModel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08cf08",
   "metadata": {},
   "source": [
    "Now we know what input parameters the `PredictModel` node needs we can start constructing our workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fa0a1",
   "metadata": {},
   "source": [
    "### Constructing the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd956cdc",
   "metadata": {},
   "source": [
    "Let's create a new instance of the `Graph` class (as we don't wish to build on top of our train workflow) and add our predict node using our local `trained_model.json` as the `model` and the `x` column of our `test_df` as the `dataset` we wish to make predictions on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the predict graph\n",
    "predict_graph = Graph()\n",
    "\n",
    "# Convert test values to CSV string\n",
    "test_input_csv = test_df[['temperature_c']].to_csv(index=False)\n",
    "\n",
    "# Define predict node with test data as input dataset and model json as model\n",
    "predict = Node(\n",
    "    node_name=\"PredictModel\",\n",
    "    label=\"Predict\",\n",
    "    dataset={\"csv\": test_input_csv},\n",
    "    model=model_json,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Add the predict node to the graph\n",
    "predict_graph.add_node(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc520276",
   "metadata": {},
   "source": [
    "We can use the `Download` node to get our resulting datasets. We will need one `Download` node for both the predictions and uncertainty output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add handles to the prediction and uncertainty outputs\n",
    "output_predictions = predict.make_handle(\"prediction\")\n",
    "output_uncertainty = predict.make_handle(\"uncertainty\")\n",
    "\n",
    "# Define download nodes for predictions and uncertainty\n",
    "download_predictions = Node(\n",
    "    node_name=\"Download\",\n",
    "    label=\"Download Predictions\",\n",
    "    file=output_predictions\n",
    ")\n",
    "download_uncertainty = Node(\n",
    "    node_name=\"Download\",\n",
    "    label=\"Download Uncertainty\",\n",
    "    file=output_uncertainty\n",
    ")\n",
    "\n",
    "# Add download nodes to the graph and connect them to the predict node\n",
    "predict_graph.add_node(download_predictions)\n",
    "predict_graph.add_node(download_uncertainty)\n",
    "\n",
    "# Print the predict graph\n",
    "pprint(predict_graph.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a47a0",
   "metadata": {},
   "source": [
    "### Executing the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f881b1",
   "metadata": {},
   "source": [
    "Now we can run our workflow using the `Workflow` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output handles for the download nodes\n",
    "output_download_predictions = download_predictions.make_handle(\"file\")\n",
    "output_download_uncertainty = download_uncertainty.make_handle(\"file\")\n",
    "\n",
    "# Wrap the predict graph in a workflow node\n",
    "predict_workflow = Workflow(\n",
    "    graph=predict_graph.nodes,\n",
    "    input=predict_graph.external_input,\n",
    "    external_input_id=predict_graph.external_input_id,\n",
    "    requested_output={\n",
    "        \"Predictions\": output_download_predictions.model_dump(),\n",
    "        \"Uncertainty\": output_download_uncertainty.model_dump(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Run the predict workflow and get the response\n",
    "predict_response = client.run_node(predict_workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159fda6",
   "metadata": {},
   "source": [
    "We can download the results and save the `predictions` and `uncertainty` as pandas dataframes so that we can plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9318ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "# Download the predictions and save as a DataFrame\n",
    "predictions_response = get_presigned_url(predict_response.outputs[\"outputs\"][\"Predictions\"])\n",
    "predictions_df = pd.read_csv(StringIO(predictions_response.text))  # Save the predictions to a DataFrame\n",
    "\n",
    "# Download the uncertainty and save as a DataFrame\n",
    "uncertainty_response = get_presigned_url(predict_response.outputs[\"outputs\"][\"Uncertainty\"])\n",
    "uncertainty_df = pd.read_csv(StringIO(uncertainty_response.text))  # Save the uncertainty to a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb9cc6",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfbd87",
   "metadata": {},
   "source": [
    "Finally, we can plot our predictions vs our truth function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3154080",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_1d(\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    predictions_df=predictions_df, \n",
    "    uncertainty_df=uncertainty_df, \n",
    "    x_col=\"temperature_c\",\n",
    "    y_col=\"comp_Fe\",\n",
    "    credible_level=0.99,\n",
    "    title=\"\",\n",
    "    x_label=\"Temperature (°C)\",\n",
    "    y_label=\"Fe composition (mass fraction)\",\n",
    "    save_path=None,  # or \"figs/fe_gp.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4253f",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb82cc5",
   "metadata": {},
   "source": [
    "Qualitatively we can see that the model predictions closely follow the ground truth. The plot also shows the uncertainty on the model predictions. As is typical for a Gaussian Process model, the uncertainty is generally larger in areas with sparse training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4ad4d",
   "metadata": {},
   "source": [
    "In this notebook we have demonstrated how to use the SDK to train a model and then use it to make predictions. \n",
    "\n",
    "If you wanted to lead on from this and get a more accurate reading of how well the model performed you could try using the `ScoreModel` node to evaluate the model. Otherwise, checkout [`demo_resource.ipynb`](./demo_resource.ipynb) to learn about how you can use resources in the Uncertainty Engine SDK."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
