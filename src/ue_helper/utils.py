from __future__ import annotations

from typing import Any, Dict, Optional, Union, Iterable

import io
import numpy as np
import pandas as pd
import requests
from pprint import pprint
from scipy.stats import norm

from uncertainty_engine_types import ResourceID
from uncertainty_engine import Client


def percentage_to_zscore(confidence_percent: float) -> float:
    """
    Convert a two-tailed confidence percentage to the corresponding z-score.

    The mapping assumes a standard normal distribution and a two-sided interval:
    z = Φ⁻¹(0.5 + p/200), where Φ is the standard normal CDF and p is the percentage.

    Examples
    --------
    68% -> 1.00
    90% -> 1.645
    95% -> 1.96
    99% -> 2.576

    Parameters
    ----------
    confidence_percent : float
        Confidence level in percent (e.g., 95 for a 95% CI).

    Returns
    -------
    float
        The corresponding z-score for a two-tailed interval.
    """
    confidence_fraction = confidence_percent / 100.0
    return float(norm.ppf(0.5 + confidence_fraction / 2.0))


def slice_dataframe(df: pd.DataFrame, freeze_param: str, value: float) -> pd.DataFrame:
    """
    Extract a slice from a multidimensional (meshgrid-flattened) DataFrame
    by fixing one parameter at a specified value.

    This reduces an N-dimensional parameter sweep (stored as a flattened DataFrame)
    to an (N–1)-dimensional slice by holding one variable constant and allowing
    all others to vary. The function:
      1) collects unique grid values for `freeze_param`,
      2) applies a small fractional offset (+0.1%) to `value` to improve matching
         in the presence of floating-point rounding,
      3) computes a tolerance equal to half the minimum positive grid spacing,
      4) selects rows where `freeze_param` is close to `value` within that tolerance.

    Parameters
    ----------
    df : pandas.DataFrame
        Full meshgrid-flattened DataFrame (all parameter combinations).
    freeze_param : str
        Column name (parameter) to hold fixed.
    value : float
        Target value for the frozen parameter (in the same units as the column).

    Returns
    -------
    pandas.DataFrame
        Subset of `df` where `freeze_param` equals (within tolerance) the requested value.
        The result has its index reset.

    Notes
    -----
    - The 0.1% delta (1e-3) helps robustly match values generated by `np.linspace`
      and similar functions in the face of tiny binary rounding differences.
    - The tolerance assumes a fairly regular grid spacing.

    Examples
    --------
    >>> sliced = slice_dataframe(df, 'li6_prop', 0.25)
    >>> sliced.shape
    """
    u = np.unique(df[freeze_param])
    delta = 1.0e-3
    value = float(value) * (1.0 + delta)
    tol = 0.5 * float(np.min(np.diff(u))) if len(u) > 1 else 1.0e-12
    sliced = df[np.isclose(df[freeze_param], value, atol=tol, rtol=0.0)].reset_index(drop=True)
    return sliced


def get_presigned_url(url: str) -> requests.Response:
    """
    Fetch the contents of a (pre-signed) URL.

    This function replaces the scheme 'https://' with 'http://' prior to the request,
    mirroring the behavior in the original code (some pre-signed endpoints may require it).

    Parameters
    ----------
    url : str
        The original (likely pre-signed) URL.

    Returns
    -------
    requests.Response
        The HTTP response object. Use `.content` / `.text` to access the payload.

    Raises
    ------
    requests.HTTPError
        If the response indicates an HTTP error status.
    """
    url = url.replace("https://", "http://")
    response = requests.get(url)
    response.raise_for_status()
    return response


def wrap_resource_id(resource_id: str) -> Dict[str, Any]:
    """
    Wrap a raw resource ID string into the `ResourceID` pydantic model's dict representation.

    Parameters
    ----------
    resource_id : str
        Raw resource ID.

    Returns
    -------
    dict
        A dictionary produced by `ResourceID(id=resource_id).model_dump()`.
    """
    return ResourceID(id=resource_id).model_dump()


def get_project_id(client: Client, project_name: str) -> str:
    """
    Resolve a project name to its unique project ID.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    project_name : str
        Human-readable project name.

    Returns
    -------
    str
        The unique project ID.

    Raises
    ------
    ValueError
        If the project name does not exist.
    """
    projects = client.projects.list_projects()
    for project in projects:
        if project.name == project_name:
            return project.id
    raise ValueError(f"Project with name {project_name!r} not found.")


def get_workflow_id(client: Client, project_name: str, workflow_name: str) -> str:
    """
    Resolve a workflow name (within a project) to its unique workflow ID.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    project_name : str
        Project name containing the workflow.
    workflow_name : str
        Human-readable workflow name.

    Returns
    -------
    str
        The unique workflow ID.

    Raises
    ------
    ValueError
        If the workflow name does not exist in the given project.
    """
    project_id = get_project_id(client, project_name)
    workflows = client.workflows.list_workflows(project_id)
    for workflow in workflows:
        if workflow.name == workflow_name:
            return workflow.id
    raise ValueError(f"Workflow with name {workflow_name!r} not found in project {project_name!r}.")


def get_resource_id(client: Client, project_name: str, resource_name: str, resource_type: str) -> str:
    """
    Resolve a resource name (within a project) to its unique resource ID.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    project_name : str
        Project name containing the resource.
    resource_name : str
        Human-readable resource name.
    resource_type : str
        Resource type (e.g., "dataset", "model", etc.).

    Returns
    -------
    str
        The unique resource ID.

    Raises
    ------
    ValueError
        If the resource name does not exist in the given project.
    """
    project_id = get_project_id(client, project_name)
    resources = client.resources.list_resources(project_id, resource_type=resource_type)
    for resource in resources:
        if resource.name == resource_name:
            return resource.id
    raise ValueError(
        f"Resource with name {resource_name!r} (type={resource_type!r}) not found in project {project_name!r}."
    )


def upload_dataset(
    client: Client,
    project_name: str,
    dataset_name: str,
    file_path: Optional[str] = None,
    dataset: Optional[Union[pd.DataFrame, Dict[str, Iterable[Any]]]] = None,
    is_replace: bool = True
) -> None:
    """
    Upload a dataset to a project, from either a CSV file on disk or an in-memory dataset.

    Behavior:
    - If `file_path` is provided, that file is uploaded.
    - Else, if `dataset` is provided, it is written to `{dataset_name}.csv` and uploaded.
    - If the upload fails and `is_replace=True`, an update call is attempted instead.
    - Prints a confirmation upon success.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    project_name : str
        Target project name.
    dataset_name : str
        Name to assign to the uploaded dataset resource.
    file_path : str, optional
        Path to a CSV file to upload.
    dataset : pandas.DataFrame or dict-like, optional
        In-memory dataset to upload. If dict-like, it will be converted to a DataFrame.
        Only used if `file_path` is None.
    is_replace : bool, default True
        If True, attempt to replace/update the existing dataset on error.

    Raises
    ------
    ValueError
        If neither `file_path` nor `dataset` is provided.
    """
    project_id = get_project_id(client, project_name)

    # Prepare a CSV on disk if only an in-memory dataset is provided.
    if file_path is None and dataset is not None:
        file_path = f"{dataset_name}.csv"
        df = dataset if isinstance(dataset, pd.DataFrame) else pd.DataFrame(dataset)
        df.to_csv(file_path, index=False)
    elif file_path is None and dataset is None:
        raise ValueError("Either `file_path` or `dataset` must be provided.")

    try:
        client.resources.upload(
            project_id=project_id,
            name=dataset_name,
            resource_type="dataset",
            file_path=file_path,
        )
    except Exception as e:
        if is_replace:
            client.resources.update(
                project_id=project_id,
                resource_id=get_resource_id(client, project_name, dataset_name, resource_type="dataset"),
                resource_type="dataset",
                file_path=file_path,
            )
        else:
            print(f"Error uploading dataset: {e}")
            return
    print(f"Uploaded {dataset_name!r} to project {project_name!r}.")


def get_node_info(client: Client, node_name: str) -> None:
    """
    Print details for a specific node by its ID/name, using the client's `list_nodes()`.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    node_name : str
        Node identifier to look up (as returned by `list_nodes()`).

    Returns
    -------
    None
        This function prints the node info to stdout.
    """
    nodes = client.list_nodes()
    nodes_by_id = {node["id"]: node for node in nodes}
    pprint(nodes_by_id[node_name])


def get_data(client: Client, project_name: str, dataset_name: str) -> pd.DataFrame:
    """
    Download a named dataset from a project and return it as a pandas DataFrame.

    Parameters
    ----------
    client : uncertainty_engine.Client
        Initialized API client.
    project_name : str
        Name of the project containing the dataset.
    dataset_name : str
        Name of the dataset resource to download.

    Returns
    -------
    pandas.DataFrame
        Parsed dataset as a DataFrame.

    Raises
    ------
    ValueError
        If the project or dataset cannot be resolved to IDs.
    """
    response: bytes = client.resources.download(
        project_id=get_project_id(client=client, project_name=project_name),
        resource_type="dataset",
        resource_id=get_resource_id(
            client=client,
            project_name=project_name,
            resource_name=dataset_name,
            resource_type="dataset",
        ),
    )
    decoded = response.decode("utf-8")
    df = pd.read_csv(io.StringIO(decoded))
    return df
